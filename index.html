<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>{{ site.title }}</title>
    <style>
        body { font-family: sans-serif; line-height: 1.6; margin: 0; color: #333; }
        /* Your Nav Bar */
        nav { background: #24292e; padding: 1rem; text-align: center; }
        nav a { color: white; margin: 0 15px; text-decoration: none; font-weight: bold; }
        .container { max-width: 800px; margin: 40px auto; padding: 0 20px; }
    </style>
</head>
<body>
    <nav>
        <a href="{{ site.baseurl }}/">Home</a>
        <a href="{{ site.baseurl }}/folder/file1.html">Doc 1</a>
        <a href="{{ site.baseurl }}/folder/file2.html">Doc 2</a>
    </nav>
    <div class="container">
        {{ content }}
    </div>
</body>

<h1 id="documentation-of-iac-incubation">documentation-of-IAC-incubation</h1>
<h2 id="the-learning-of-one-month-at-the-thimphu-tech-park-incubating-under-the-information-access-center-iac-">the learning of one month at the Thimphu tech park, incubating under the Information Access Center (IAC)</h2>
<p>This repository is to document my learnings during the one month incubation period at the IAC. This is a day by day documentation on the month one learning period.</p>
<p>The documentation would mainly be for proper understanding, citations and future replicability. I myself will document this the entire months learnings with the upmost depth as possible.</p>
<p>The mile stone that I hope to achieve with this incubation is to properly understand the workings of ai and be able to finetune an preexisting ai model to suit my requirements.</p>
<p>My initial roadmap was to create and train a dully functional Dzongkha LLM, though after learning more and understanding the vast complexities it composed of, I decided against it.</p>
<p>Currently, I plan on learning how to fine tune a preexisting ai model on the data I provide to be able to respond to my questions with the knowledge that I provide. I plan on using the Retrieval Augmented Generation pipline (RAG) which is where you provide the knowledge and data to an preexisting ai model. Through this it is possible for the ai to answer questions that is not originally in its data base as it first read the documents before providing the answer to our questions.</p>
<p>With RAG, my first aim is to understand the workflow and  backend workings of this method. For this I decided to train the llama3.1:8b (3.1 is the model version, and the 8b indicates the model has a total of 8 billion parameters) on the Bhutan baccalaureate learning process pdf. </p>
<p>Then The last step would be to plan and create a road map on how to start fine tuning a dzongkha LLM.</p>

</html>
